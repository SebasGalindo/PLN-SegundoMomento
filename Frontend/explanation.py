import streamlit as st

st.title("üìù Explicaci√≥n: Algoritmo Gen√©tico Adaptativo para Distancia entre Paneles Solares")

st.markdown("""
**Objetivo base**: Optimizar la distancia m√≠nima entre paneles solares fotovoltaicos del tipo A-135P (1476√ó659√ó35 mm) instalados a una latitud de 41¬∞, inclinados 45¬∞, para evitar sombras en invierno y reducir distancia en verano.

Este problema se plantea en el PDF del Taller AGA, donde se define:

- C√°lculo de la elevaci√≥n solar cr√≠tica:
  - Invierno: $\\alpha_{inv}=(90^\circ-\\varphi)-23.45^\circ$
  - Verano:  $\\alpha_{ver}=(90^\circ-\\varphi)+23.45^\circ$
- F√≥rmula de distancia m√≠nima:
  $D_M = B\cos\\beta + \\frac{B\sin\\beta}{\\tan\\alpha}$
  
  Donde:
  - **B**: longitud del panel (1476 mm)
  - **Œ≤**: √°ngulo de inclinaci√≥n (45¬∞)
  - **Œ±**: elevaci√≥n solar cr√≠tica (invierno/verano)
""", unsafe_allow_html=True)

st.header("1. Representaci√≥n y Fitness")
st.markdown("""
- **Cromosoma**: un valor real `D` (distancia en mm).
- **Fitness**: mide la cercan√≠a al valor √≥ptimo te√≥rico:

```python
def fitness(D, D_opt):
    return abs(D - D_opt)
```
""", unsafe_allow_html=True)

st.header("2. Selecci√≥n por Torneo")
st.markdown("Se eligen aleatoriamente un subconjunto de la poblaci√≥n y se selecciona el individuo con menor fitness (porque se busca la distancia minima):")
st.code("""def ranking_selection(pob, D_opt, pct):
    import random
    sub = random.sample(pob, int(len(pob)*pct))
    return min(sub, key=lambda x: abs(x - D_opt))
""", language='python')

st.header("3. Cruce y Mutaci√≥n")
st.subheader("3.1 Cruce Aritm√©tico")
st.markdown("""
             Simple de implementar y genera hijos en el rango $[P_1, P_2]$ , el problema es que puede reducir la diversidad si siempre mezcla de la misma forma.

  Ecuaci√≥n: 
  $H_1 = Œ± * P_1 + (1 - Œ±)P_2$, $H_2 = (1 - Œ±)P_1 + Œ± * P_2$

  donde Œ± es un valor fijo o aleatorio entre 0 y 1

  referencia: https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_crossover.htm
  """)
st.code("""def arithmetic_crossover(p1, p2, alpha=None):
    import random
    if alpha is None:
        alpha = random.random()
    return (alpha*p1 + (1-alpha)*p2,
            (1-alpha)*p1 + alpha*p2)
""", language='python')

st.subheader("3.2 BLX-Œ±")
st.markdown("""
            
  Para cada cruce, extiende el intervalo $[P_{min}, P_{max}]$ en un factor Œ±

  $ I = P_{min} - P_{max} $ y tambien se calcula el $margen = Œ± * I$ 

  luego se muestrea cada hijo uniformemente en $[P_{min} - margen, P_{max} - margen]$

  el valor de Œ± es entre (0,1)
  tiene un problema cuando Œ± es muy grande por que los hijos se alejan mucho agregando ruido.
  
  referencia: http://www.tomaszgwiazda.com/blendX.htm
    """)

st.code("""def blx_alpha(p1, p2, alpha=0.3):
    import random
    lo, hi = min(p1,p2), max(p1,p2)
    d = hi - lo
    return (random.uniform(lo - alpha*d, hi + alpha*d),
            random.uniform(lo - alpha*d, hi + alpha*d))
""", language='python')

st.subheader("3.3 SBX (Simulated Binary Crossover)")
st.markdown("""
              En este m√©todo se imitan cruces binarios usando un √≠ndice de distribuci√≥n ∆û.
  se calcula un factor Œ≤ seg√∫n una distribuci√≥bn coontrolada por ∆û.

  este m√©todo es muy usado en GAs reales gracias a que balancea exploraci√≥n/explotaci√≥n seg√∫n ∆û que normalmente tiene vales entre 2 y 5.

  Ecuaci√≥n:
  $h_1 = 0.5[(1 + Œ≤) * p_1 + (1 - Œ≤) * p_2 ]$ y $h_2 = 0.5[(1 - Œ≤) * p_1 + (1 + Œ≤) * p_2 ]$

  reference: https://www.researchgate.net/publication/220742263_Self-adaptive_simulated_binary_crossover_for_real-parameter_optimization
    """)

st.code("""def sbx(p1, p2, eta=2):
    import random
    u = random.random()
    if u <= 0.5:
        beta = (2*u)**(1/(eta+1))
    else:
        beta = (1/(2*(1-u)))**(1/(eta+1))
    return (0.5*((1+beta)*p1 + (1-beta)*p2),
            0.5*((1-beta)*p1 + (1+beta)*p2))
""", language='python')

st.subheader("3.4 Mutaci√≥n Gaussiana")
st.markdown("""
              Suma ruido gaussiano truncado al individuo original para no salirse de los l√≠mites.
  
  Ecuaci√≥n:
  $D' = D + N(0,Œ¥)$ ‚áí Truncado a $[D_{min},D_m{max}]$

  este m√©todo es √∫til porque permite un control fino de la magnitud de la perturbaci√≥n con Œ¥ aunque si este valor es muy grande puede comportarse como mutaci√≥n aleatoria.
    """)
st.code("""def gaussian_mutation(D, D_min, D_max, sigma=500):
    import random
    Dp = D + random.gauss(0, sigma)
    return min(max(Dp, D_min), D_max)
""", language='python')

st.subheader("3.5 Mutaci√≥n Polin√≥mica")
st.markdown("""
            Se Utiliza una distribuci√≥n polin√≥mica controlada por un √≠ndice $∆û_m$
  para generar mutaciones preferentemente peque√±as.

  para esto se hacen los siguientes calculos:
  1. Generar un valor u entre (0,1)
  2. Calcular el Œ¥ para la mutaci√≥n mediante:
  """)
st.latex(r"""
  \begin{equation}\delta =
  \begin{cases}
  (2u)^{\frac{1}{\eta_m + 1}} - 1, & \text{si } u < 0.5 \\
  1 - [2(1 - u)]^{\frac{1}{\eta_m + 1}}, & \text{si } u \geq 0.5
  \end{cases}
  \end{equation}
  """)
  
st.markdown("""
  3. Calcular la mutaci√≥n
  """)

st.latex(r"""
           \begin{equation}D' = D + Œ¥ x 
  \begin{cases}
    D - D_{min}, & Œ¥ < 0 \\
    D_{max} - D, & Œ¥ ‚â• 0 
  \end{cases}
  \end{equation}
    """)
  
st.code("""def polynomial_mutation(D, D_min, D_max, eta_m=20):
    import random
    u = random.random()
    if u < 0.5:
        delta = (2*u)**(1/(1+eta_m)) - 1
    else:
        delta = 1 - (2*(1-u))**(1/(1+eta_m))
    if delta < 0:
        Dp = D + delta*(D - D_min)
    else:
        Dp = D + delta*(D_max - D)
    return min(max(Dp, D_min), D_max)
""", language='python')

st.header("4. Adaptaci√≥n de Par√°metros")
st.markdown("""
Existen diferentes m√©todos de adaptaci√≥n pero se decide implementar 2 (basado en diversidad de poblaci√≥n y basado en tasa de mejora del fitness) para que el usuario escoga cual de las dos opciones desea utilizar para hacer adaptativas las probabilidades de mutaci√≥n y cruce.

1. **Basado en diversidad**:
    
    La idea es medir la diversidad 'D' como la desviaci√≥n est√°ndar media de cada individuo en la poblaci√≥n, por lo que las probabilidades de mutaci√≥n ($p_m$) y cruce ($p_c$) se ajustan seg√∫n:
""")
st.latex(r"""
     \begin{equation}
   p_m(D) = p_{m,min} + (p_{m,max} - p_{m,min}) e^{-k_mD} 
    \end{equation}
    """)
st.latex(r"""
    \begin{equation}
   p_c(D) = p_{c,max} + (p_{c,max} - p_{c,min}) e^{-k_cD}
  \end{equation}
""")      
st.markdown("""
      Entonces cuando la poblaci√≥n es muy homogenea ('D' es peque√±o), $P_m$ tiende hacia su valor maximo y $P_c$ tiende a menos valor para menor cruce, por el contrario si la poblaci√≥n es diversa el valor de la probabilidad de cruce aumenta y la de mutaci√≥n disminuye.
            
   ```python
   import statistics, math
   D = statistics.pstdev(poblacion)
   pm = pm_min + (pm_max-pm_min)*math.exp(-k_m*D)
   pc = pc_max - (pc_max-pc_min)*math.exp(-k_c*D)
   ```

2. **Basado en tasa de mejora**:

  En este m√©todo la idea es calcular la mejora relativa del fitness promedio entre generaciones:
  
    """)
st.latex(r"""
           \begin{equation}
    ŒîF = \frac{f_{t-1} - f_t}{f_{t-1}}
  \end{equation}
""")
st.markdown("""
  luego se ajusta con:
    """)
st.latex(r"""
  \begin{equation}
    p_m(ŒîF) = p_{m,min} + (p_{m,max} - p_{m,min}) (1 - ŒîF) 
    \end{equation}
""")
st.latex(r"""
\begin{equation}
    p_c(ŒîF) = p_{c,min} + (p_{c,max} - p_{c,min}) ŒîF
  \end{equation}
""")
st.markdown("""
   ```python
   fit_prev = avg_fitness(poblacion, D_opt)
   fit_curr = avg_fitness(nueva_pob, D_opt)
   deltaF = (fit_prev - fit_curr)/fit_prev
   pm = pm_min + (pm_max-pm_min)*(1 - deltaF)
   pc = pc_min + (pc_max-pc_min)*deltaF
   ```
""", unsafe_allow_html=True)

