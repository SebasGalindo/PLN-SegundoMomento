{
  "best_global_step": 3208,
  "best_metric": 0.9992982456140351,
  "best_model_checkpoint": "/kaggle/working/modelo_ner_frases/checkpoint-3208",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 3208,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06234413965087282,
      "grad_norm": 5.3197736740112305,
      "learning_rate": 2.963341645885287e-05,
      "loss": 1.0451,
      "step": 50
    },
    {
      "epoch": 0.12468827930174564,
      "grad_norm": 2.7888903617858887,
      "learning_rate": 2.925935162094763e-05,
      "loss": 0.2688,
      "step": 100
    },
    {
      "epoch": 0.18703241895261846,
      "grad_norm": 1.5975918769836426,
      "learning_rate": 2.8885286783042394e-05,
      "loss": 0.114,
      "step": 150
    },
    {
      "epoch": 0.24937655860349128,
      "grad_norm": 0.8478397727012634,
      "learning_rate": 2.8511221945137157e-05,
      "loss": 0.0321,
      "step": 200
    },
    {
      "epoch": 0.3117206982543641,
      "grad_norm": 0.060075316578149796,
      "learning_rate": 2.813715710723192e-05,
      "loss": 0.0114,
      "step": 250
    },
    {
      "epoch": 0.3740648379052369,
      "grad_norm": 0.12618453800678253,
      "learning_rate": 2.7763092269326682e-05,
      "loss": 0.0107,
      "step": 300
    },
    {
      "epoch": 0.43640897755610975,
      "grad_norm": 0.09080926328897476,
      "learning_rate": 2.7389027431421445e-05,
      "loss": 0.0149,
      "step": 350
    },
    {
      "epoch": 0.49875311720698257,
      "grad_norm": 0.366639107465744,
      "learning_rate": 2.701496259351621e-05,
      "loss": 0.0204,
      "step": 400
    },
    {
      "epoch": 0.5610972568578554,
      "grad_norm": 0.05917305499315262,
      "learning_rate": 2.6640897755610973e-05,
      "loss": 0.0062,
      "step": 450
    },
    {
      "epoch": 0.6234413965087282,
      "grad_norm": 0.013740304857492447,
      "learning_rate": 2.6266832917705736e-05,
      "loss": 0.0067,
      "step": 500
    },
    {
      "epoch": 0.685785536159601,
      "grad_norm": 0.016475697979331017,
      "learning_rate": 2.5892768079800498e-05,
      "loss": 0.0046,
      "step": 550
    },
    {
      "epoch": 0.7481296758104738,
      "grad_norm": 0.02398940734565258,
      "learning_rate": 2.551870324189526e-05,
      "loss": 0.0038,
      "step": 600
    },
    {
      "epoch": 0.8104738154613467,
      "grad_norm": 0.025483008474111557,
      "learning_rate": 2.5144638403990023e-05,
      "loss": 0.0072,
      "step": 650
    },
    {
      "epoch": 0.8728179551122195,
      "grad_norm": 0.04110619053244591,
      "learning_rate": 2.4770573566084786e-05,
      "loss": 0.01,
      "step": 700
    },
    {
      "epoch": 0.9351620947630923,
      "grad_norm": 1.023216724395752,
      "learning_rate": 2.4396508728179552e-05,
      "loss": 0.0104,
      "step": 750
    },
    {
      "epoch": 0.9975062344139651,
      "grad_norm": 1.003209114074707,
      "learning_rate": 2.4022443890274315e-05,
      "loss": 0.0074,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_f1_macro": 0.9419977870546113,
      "eval_f1_weighted": 0.9352247873695316,
      "eval_loss": 0.01583489216864109,
      "eval_precision_macro": 0.9336782130569479,
      "eval_precision_weighted": 0.9238563975768743,
      "eval_recall_macro": 0.9510428105167816,
      "eval_recall_weighted": 0.9473684210526315,
      "eval_runtime": 8.4649,
      "eval_samples_per_second": 168.342,
      "eval_steps_per_second": 10.632,
      "step": 802
    },
    {
      "epoch": 1.059850374064838,
      "grad_norm": 3.2661995887756348,
      "learning_rate": 2.3648379052369077e-05,
      "loss": 0.0065,
      "step": 850
    },
    {
      "epoch": 1.1221945137157108,
      "grad_norm": 0.0761624202132225,
      "learning_rate": 2.327431421446384e-05,
      "loss": 0.0035,
      "step": 900
    },
    {
      "epoch": 1.1845386533665836,
      "grad_norm": 0.021458055824041367,
      "learning_rate": 2.2900249376558602e-05,
      "loss": 0.0024,
      "step": 950
    },
    {
      "epoch": 1.2468827930174564,
      "grad_norm": 0.011407520622015,
      "learning_rate": 2.2526184538653365e-05,
      "loss": 0.0044,
      "step": 1000
    },
    {
      "epoch": 1.3092269326683292,
      "grad_norm": 0.0051197633147239685,
      "learning_rate": 2.215211970074813e-05,
      "loss": 0.0031,
      "step": 1050
    },
    {
      "epoch": 1.371571072319202,
      "grad_norm": 0.03070721961557865,
      "learning_rate": 2.1778054862842893e-05,
      "loss": 0.0044,
      "step": 1100
    },
    {
      "epoch": 1.4339152119700749,
      "grad_norm": 0.07305833697319031,
      "learning_rate": 2.1403990024937656e-05,
      "loss": 0.0017,
      "step": 1150
    },
    {
      "epoch": 1.4962593516209477,
      "grad_norm": 0.0036619952879846096,
      "learning_rate": 2.102992518703242e-05,
      "loss": 0.0013,
      "step": 1200
    },
    {
      "epoch": 1.5586034912718203,
      "grad_norm": 0.016934935003519058,
      "learning_rate": 2.065586034912718e-05,
      "loss": 0.0022,
      "step": 1250
    },
    {
      "epoch": 1.6209476309226933,
      "grad_norm": 0.2911747694015503,
      "learning_rate": 2.0281795511221944e-05,
      "loss": 0.0044,
      "step": 1300
    },
    {
      "epoch": 1.683291770573566,
      "grad_norm": 1.357284426689148,
      "learning_rate": 1.9907730673316706e-05,
      "loss": 0.005,
      "step": 1350
    },
    {
      "epoch": 1.745635910224439,
      "grad_norm": 0.011059204116463661,
      "learning_rate": 1.9533665835411472e-05,
      "loss": 0.0034,
      "step": 1400
    },
    {
      "epoch": 1.8079800498753116,
      "grad_norm": 1.4031535387039185,
      "learning_rate": 1.9159600997506235e-05,
      "loss": 0.003,
      "step": 1450
    },
    {
      "epoch": 1.8703241895261846,
      "grad_norm": 0.014548090286552906,
      "learning_rate": 1.8785536159600997e-05,
      "loss": 0.0036,
      "step": 1500
    },
    {
      "epoch": 1.9326683291770572,
      "grad_norm": 0.003760774154216051,
      "learning_rate": 1.841147132169576e-05,
      "loss": 0.0035,
      "step": 1550
    },
    {
      "epoch": 1.9950124688279303,
      "grad_norm": 0.024440880864858627,
      "learning_rate": 1.8037406483790523e-05,
      "loss": 0.0016,
      "step": 1600
    },
    {
      "epoch": 2.0,
      "eval_f1_macro": 0.9984907032233308,
      "eval_f1_weighted": 0.9982446882377448,
      "eval_loss": 0.0009090463863685727,
      "eval_precision_macro": 0.9988205185267609,
      "eval_precision_weighted": 0.9985964912280701,
      "eval_recall_macro": 0.9981626237899188,
      "eval_recall_weighted": 0.9978947368421053,
      "eval_runtime": 8.4252,
      "eval_samples_per_second": 169.135,
      "eval_steps_per_second": 10.682,
      "step": 1604
    },
    {
      "epoch": 2.057356608478803,
      "grad_norm": 0.002463104436174035,
      "learning_rate": 1.7663341645885285e-05,
      "loss": 0.002,
      "step": 1650
    },
    {
      "epoch": 2.119700748129676,
      "grad_norm": 0.010510583408176899,
      "learning_rate": 1.7289276807980048e-05,
      "loss": 0.0013,
      "step": 1700
    },
    {
      "epoch": 2.1820448877805485,
      "grad_norm": 0.0025304965674877167,
      "learning_rate": 1.6915211970074814e-05,
      "loss": 0.003,
      "step": 1750
    },
    {
      "epoch": 2.2443890274314215,
      "grad_norm": 0.0033700792118906975,
      "learning_rate": 1.6541147132169576e-05,
      "loss": 0.0019,
      "step": 1800
    },
    {
      "epoch": 2.306733167082294,
      "grad_norm": 0.0017029825830832124,
      "learning_rate": 1.616708229426434e-05,
      "loss": 0.0007,
      "step": 1850
    },
    {
      "epoch": 2.369077306733167,
      "grad_norm": 0.02187764272093773,
      "learning_rate": 1.57930174563591e-05,
      "loss": 0.002,
      "step": 1900
    },
    {
      "epoch": 2.43142144638404,
      "grad_norm": 0.002198051428422332,
      "learning_rate": 1.5418952618453864e-05,
      "loss": 0.0004,
      "step": 1950
    },
    {
      "epoch": 2.493765586034913,
      "grad_norm": 0.002020640764385462,
      "learning_rate": 1.5044887780548628e-05,
      "loss": 0.0007,
      "step": 2000
    },
    {
      "epoch": 2.5561097256857854,
      "grad_norm": 0.004043879918754101,
      "learning_rate": 1.4670822942643392e-05,
      "loss": 0.0007,
      "step": 2050
    },
    {
      "epoch": 2.6184538653366585,
      "grad_norm": 0.009569392539560795,
      "learning_rate": 1.4296758104738155e-05,
      "loss": 0.0012,
      "step": 2100
    },
    {
      "epoch": 2.680798004987531,
      "grad_norm": 0.0021993510890752077,
      "learning_rate": 1.3922693266832918e-05,
      "loss": 0.0003,
      "step": 2150
    },
    {
      "epoch": 2.743142144638404,
      "grad_norm": 0.001583027420565486,
      "learning_rate": 1.3548628428927682e-05,
      "loss": 0.0011,
      "step": 2200
    },
    {
      "epoch": 2.8054862842892767,
      "grad_norm": 0.0018103192560374737,
      "learning_rate": 1.3174563591022444e-05,
      "loss": 0.0002,
      "step": 2250
    },
    {
      "epoch": 2.8678304239401498,
      "grad_norm": 0.0024409336037933826,
      "learning_rate": 1.2800498753117207e-05,
      "loss": 0.002,
      "step": 2300
    },
    {
      "epoch": 2.9301745635910224,
      "grad_norm": 0.001741744577884674,
      "learning_rate": 1.2426433915211971e-05,
      "loss": 0.0004,
      "step": 2350
    },
    {
      "epoch": 2.9925187032418954,
      "grad_norm": 0.001977390144020319,
      "learning_rate": 1.2052369077306734e-05,
      "loss": 0.0005,
      "step": 2400
    },
    {
      "epoch": 3.0,
      "eval_f1_macro": 0.9987010796221323,
      "eval_f1_weighted": 0.9985964912280701,
      "eval_loss": 0.0012620792258530855,
      "eval_precision_macro": 0.9987010796221323,
      "eval_precision_weighted": 0.9985964912280701,
      "eval_recall_macro": 0.9987010796221323,
      "eval_recall_weighted": 0.9985964912280701,
      "eval_runtime": 8.4288,
      "eval_samples_per_second": 169.064,
      "eval_steps_per_second": 10.678,
      "step": 2406
    },
    {
      "epoch": 3.054862842892768,
      "grad_norm": 0.002558442996814847,
      "learning_rate": 1.1678304239401496e-05,
      "loss": 0.0002,
      "step": 2450
    },
    {
      "epoch": 3.117206982543641,
      "grad_norm": 0.0019310935167595744,
      "learning_rate": 1.1304239401496259e-05,
      "loss": 0.0002,
      "step": 2500
    },
    {
      "epoch": 3.1795511221945136,
      "grad_norm": 0.0012942738831043243,
      "learning_rate": 1.0930174563591023e-05,
      "loss": 0.0002,
      "step": 2550
    },
    {
      "epoch": 3.2418952618453867,
      "grad_norm": 0.001233054674230516,
      "learning_rate": 1.0556109725685786e-05,
      "loss": 0.0002,
      "step": 2600
    },
    {
      "epoch": 3.3042394014962593,
      "grad_norm": 0.001542694866657257,
      "learning_rate": 1.0182044887780548e-05,
      "loss": 0.0008,
      "step": 2650
    },
    {
      "epoch": 3.3665835411471323,
      "grad_norm": 0.0029468813445419073,
      "learning_rate": 9.807980049875313e-06,
      "loss": 0.0002,
      "step": 2700
    },
    {
      "epoch": 3.428927680798005,
      "grad_norm": 0.0037734375800937414,
      "learning_rate": 9.433915211970075e-06,
      "loss": 0.0013,
      "step": 2750
    },
    {
      "epoch": 3.491271820448878,
      "grad_norm": 0.001238444121554494,
      "learning_rate": 9.059850374064838e-06,
      "loss": 0.0002,
      "step": 2800
    },
    {
      "epoch": 3.5536159600997506,
      "grad_norm": 0.0031639335211366415,
      "learning_rate": 8.6857855361596e-06,
      "loss": 0.0002,
      "step": 2850
    },
    {
      "epoch": 3.6159600997506236,
      "grad_norm": 0.0029402393847703934,
      "learning_rate": 8.311720698254365e-06,
      "loss": 0.0002,
      "step": 2900
    },
    {
      "epoch": 3.678304239401496,
      "grad_norm": 0.0012798336101695895,
      "learning_rate": 7.937655860349127e-06,
      "loss": 0.0005,
      "step": 2950
    },
    {
      "epoch": 3.7406483790523692,
      "grad_norm": 0.0009675247711129487,
      "learning_rate": 7.563591022443891e-06,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 3.802992518703242,
      "grad_norm": 0.0016911880811676383,
      "learning_rate": 7.189526184538653e-06,
      "loss": 0.0001,
      "step": 3050
    },
    {
      "epoch": 3.8653366583541144,
      "grad_norm": 0.0011429332662373781,
      "learning_rate": 6.815461346633417e-06,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 3.9276807980049875,
      "grad_norm": 0.000997314346022904,
      "learning_rate": 6.441396508728179e-06,
      "loss": 0.0001,
      "step": 3150
    },
    {
      "epoch": 3.9900249376558605,
      "grad_norm": 0.0011999491835013032,
      "learning_rate": 6.067331670822943e-06,
      "loss": 0.0003,
      "step": 3200
    },
    {
      "epoch": 4.0,
      "eval_f1_macro": 0.9993589743589744,
      "eval_f1_weighted": 0.9992982456140351,
      "eval_loss": 0.000709615764208138,
      "eval_precision_macro": 0.9993589743589744,
      "eval_precision_weighted": 0.9992982456140351,
      "eval_recall_macro": 0.9993589743589744,
      "eval_recall_weighted": 0.9992982456140351,
      "eval_runtime": 8.7688,
      "eval_samples_per_second": 162.508,
      "eval_steps_per_second": 10.264,
      "step": 3208
    }
  ],
  "logging_steps": 50,
  "max_steps": 4010,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3350017372529664.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
